<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ -->
<meta name="description" content="">
<meta name="author" content="">
<link rel="icon" href="../img/favicon.ico">
<title>原理说明</title>
<script src="../js/jquery.min.js"></script>
<script src="../js/bootstrap.min.js"></script>
<link rel="stylesheet" href="../css/bootstrap.min.css">
<link rel="stylesheet" href="../css/bootstrap-theme.min.css">
</head>
<body>
	<!-- Fixed navbar -->
	<nav class="navbar navbar-inverse navbar-fixed-top" style="background: rgb(8, 8, 8);">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle collapsed"
					data-toggle="collapse" data-target="#navbar" aria-expanded="false"
					aria-controls="navbar">
					<span class="sr-only">Toggle navigation</span> <span
						class="icon-bar"></span> <span class="icon-bar"></span> <span
						class="icon-bar"></span>
				</button>
				<a class="navbar-brand" href="../../index.html" style="color: rgb(255, 255, 255);">定制爬虫</a>
			</div>
		</div>
	</nav>
	<div class="container theme-showcase" role="main">
		<!-- Main jumbotron for a primary marketing message or call to action -->
		<div class="jumbotron">
			<h1>爬虫简介</h1>
		</div>
		<div class="blog-post">
			<h2 class="blog-post-title">原理简介</h2>
			<p class="blog-post-meta">
				2012-06-18 by <a
					href="https://www.cnblogs.com/wawlian/archive/2012/06/18/2553061.html"
					target="_blank">Wawlian</a>
			</p>
			<hr>
			<p style="text-indent: 2em">网络爬虫是捜索引擎抓取系统的重要组成部分。爬虫的主要目的是将互联网上的网页下载到本地形成一个或联网内容的镜像备份。</p>
			<p>一、网络爬虫的基本结构及工作流程</p>
			<p style="text-indent: 2em">一个通用的网络爬虫的框架如图所示：</p>
			<div class="container" style="margin-bottom: 10px">
				<img src="../img/principle1.png" alt="principle1"
					class="img-thumbnail">
			</div>
			<p style="text-indent: 2em">网络爬虫的基本工作流程如下：</p>
			<ol>
				<li>首先选取一部分精心挑选的种子URL；</li>
				<li>将这些URL放入待抓取URL队列；</li>
				<li>从待抓取URL队列中取出待抓取在URL，解析DNS，并且得到主机的ip，并将URL对应的网页下载下来，存储进已下载网页库中。此外，将这些URL放进已抓取URL队列。</li>
				<li>分析已抓取URL队列中的URL，分析其中的其他URL，并且将URL放入待抓取URL队列，从而进入下一个循环。</li>
			</ol>
			<p>二、从爬虫的角度对互联网进行划分</p>
			<p style="text-indent: 2em">对应的，可以将互联网的所有页面分为五个部分：</p>
			<div class="container" style="margin-bottom: 10px">
				<img src="../img/principle2.png" alt="principle2"
					class="img-thumbnail">
			</div>
			<ol>
				<li>已下载未过期网页</li>
				<li>已下载已过期网页：抓取到的网页实际上是互联网内容的一个镜像与备份，互联网是动态变化的，一部分互联网上的内容已经发生了变化，这时，这部分抓取到的网页就已经过期了。</li>
				<li>待下载网页：也就是待抓取URL队列中的那些页面</li>
				<li>可知网页：还没有抓取下来，也没有在待抓取URL队列中，但是可以通过对已抓取页面或者待抓取URL对应页面进行分析获取到的URL，认为是可知网页。</li>
				<li>还有一部分网页，爬虫是无法直接抓取下载的。称为不可知网页。</li>
			</ol>
			<p>三、抓取策略</p>
			<p style="text-indent: 2em">在爬虫系统中，待抓取URL队列是很重要的一部分。待抓取URL队列中的URL以什么样的顺序排列也是一个很重要的问题，因为这涉及到先抓取那个页面，后抓取哪个页面。而决定这些URL排列顺序的方法，叫做抓取策略。下面重点介绍几种常见的抓取策略：</p>
			<ol>
				<li>深度优先遍历策略</li>
				<p>深度优先遍历策略是指网络爬虫会从起始页开始，一个链接一个链接跟踪下去，处理完这条线路之后再转入下一个起始页，继续跟踪链接。我们以下面的图为例：</p>
				<div class="container" style="margin-bottom: 10px">
					<img src="../img/principle3.png" alt="principle3"
						class="img-thumbnail">
				</div>
				<p>遍历的路径：A-F-G E-H-I B C D</p>
				<li>宽度优先遍历策略</li>
				<p>宽度优先遍历策略的基本思路是，将新下载网页中发现的链接直接插入待抓取URL队列的末尾。也就是指网络爬虫会先抓取起始网页中链接的所有网页，然后再选择其中的一个链接网页，继续抓取在此网页中链接的所有网页。还是以上面的图为例：</p>
				<p>遍历路径：A-B-C-D-E-F G H I</p>
				<li>反向链接数策略</li>
				<p>反向链接数是指一个网页被其他网页链接指向的数量。反向链接数表示的是一个网页的内容受到其他人的推荐的程度。因此，很多时候搜索引擎的抓取系统会使用这个指标来评价网页的重要程度，从而决定不同网页的抓取先后顺序。</p>
				<p>在真实的网络环境中，由于广告链接、作弊链接的存在，反向链接数不能完全等他我那个也的重要程度。因此，搜索引擎往往考虑一些可靠的反向链接数。</p>
				<li>Partial PageRank策略</li>
				<p>Partial
					PageRank算法借鉴了PageRank算法的思想：对于已经下载的网页，连同待抓取URL队列中的URL，形成网页集合，计算每个页面的PageRank值，计算完之后，将待抓取URL队列中的URL按照PageRank值的大小排列，并按照该顺序抓取页面。</p>
				<p>如果每次抓取一个页面，就重新计算PageRank值，一种折中方案是：每抓取K个页面后，重新计算一次PageRank值。但是这种情况还会有一个问题：对于已经下载下来的页面中分析出的链接，也就是我们之前提到的未知网页那一部分，暂时是没
					有PageRank值的。为了解决这个问题，会给这些页面一个临时的PageRank值：将这个网页所有入链传递进来的PageRank值进行汇总，这样就形成了该未知页面的PageRank值，从而参与排序。下面举例说明：</p>
				<li>OPIC策略策略</li>
				<p>该算法实际上也是对页面进行一个重要性打分。在算法开始前，给所有页面一个相同的初始现金（cash）。当下载了某个页面P之后，将P的现金分摊给所有从P中分析出的链接，并且将P的现金清空。对于待抓取URL队列中的所有页面按照现金数进行排序。</p>
				<li>大站优先策略</li>
				<p>对于待抓取URL队列中的所有网页，根据所属的网站进行分类。对于待下载页面数多的网站，优先下载。这个策略也因此叫做大站优先策略。</p>
			</ol>
		</div>
		<div class="blog-post">
			<h2 class="blog-post-title">后台程序说明</h2>
			<hr>
			<p style="text-indent: 2em">后台程序由Java语言开发，主要分为两个部分：核心爬虫jar包和一个web服务，它们都部署在linux服务器上。当前端页面的参数被正确输入之后，web服务的后台接口会解析这些参数，组装成一个shell命令，最终该命令会调
				用核心爬虫jar包，并根据约定将爬取的数据解析，存储以备后续使用。</p>
			<p style="text-indent: 2em">
				在<a href="seed.html" target="_blank">参数配置页面</a>中，根据提示填写好相关的参数，点击页面中的开始爬虫按钮，后台接口会将生成的命令与执行结果返回于按钮下的文本展示中。为了能够更准确地填写参数，可以在<a
					href="test.html" target="_blank">测试页面</a>中进行网页内容的提取测试，查看返回的解析结果，从而准确地找出指定爬取内容的匹配标签。这里给出关键代码：
			</p>
			<pre>
			<code>Document doc = Jsoup.parse(html);
			Elements elements = doc.select(keywords);
			String parseResult = elements.text();</code>
			</pre>
			<p>
				这里的html就是从网页上爬取的内容，作为一个参数被传进解析函数中。keywords就是用户通过页面传入的关键字，传入通过select选择器进行内容匹配，最后的parseResult即根据页面标签提取出来的内容。
				如果对JSoup的select选择器不够了解，可以查看<a
					href="https://jsoup.org/cookbook/extracting-data/selector-syntax"
					target="_blank"> Jsoup的selector选择器</a>，再通过测试页面进行练习测试，等完全掌握了该种匹配方法，即可填写参数，进行指定页面的爬虫。
			</p>
		</div>
		<hr>
		<footer>
			<script type="text/javascript" src="../js/footer.js"></script>
		</footer>
	</div>
</body>
</html>